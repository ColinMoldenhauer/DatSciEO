{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports:\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from dataset import TreeClassifDataset, TreeClassifPreprocessedDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total length of dataset: 43944 \n",
      "Shape of sample: 5x5 pixels over 29 bands - (29, 5, 5)\n",
      "Classes: ['Acer_pseudoplatanus', 'Acer_pseudoplatanus', 'Acer_pseudoplatanus', 'Acer_pseudoplatanus', 'Betula_pendula', 'Carpinus_betulus', 'Fagus_sylvatica', 'Fagus_sylvatica', 'Fagus_sylvatica', 'Fagus_sylvatica']\n"
     ]
    }
   ],
   "source": [
    "# Load and prepare data:\n",
    "\n",
    "path = 'c:/Users/user/OneDrive/Dokumente/TUM/WS23/Data_Science_in_EO/DatSciEO/'\n",
    "\n",
    "trees_dataset = TreeClassifPreprocessedDataset(f\"{path}data/1123_delete_nan_samples_B2\")\n",
    "total_samples = len(trees_dataset)\n",
    "input_shape = trees_dataset[0][0].shape\n",
    "\n",
    "n_classes = trees_dataset[-1][1] + 1\n",
    "n_channels = input_shape[0]\n",
    "class_labels = [trees_dataset.label_to_labelname(trees_dataset[0][1]), trees_dataset.label_to_labelname(trees_dataset[480][1]), trees_dataset.label_to_labelname(trees_dataset[949][1]), trees_dataset.label_to_labelname(trees_dataset[1635][1]),\n",
    "                trees_dataset.label_to_labelname(trees_dataset[3328][1]), trees_dataset.label_to_labelname(trees_dataset[3847][1]), trees_dataset.label_to_labelname(trees_dataset[6651][1]), trees_dataset.label_to_labelname(trees_dataset[9198][1]),\n",
    "                trees_dataset.label_to_labelname(trees_dataset[10123][1]), trees_dataset.label_to_labelname(trees_dataset[10781][1])]\n",
    "\n",
    "print(f\"\\nTotal length of dataset: {total_samples} \\nShape of sample: {input_shape[1]}x{input_shape[2]} pixels over {n_channels} bands - {input_shape}\")\n",
    "print(\"Classes:\", class_labels)\n",
    "# print(\"\\nClasses:\")\n",
    "# label = 200\n",
    "# for i in range(total_samples):\n",
    "    \n",
    "#     if trees_dataset[i][1] != label:\n",
    "#         label = trees_dataset[i][1]\n",
    "#         print(label, trees_dataset.label_to_labelname(label))\n",
    "\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "data_train, data_val = random_split(trees_dataset, [0.8, 0.2], generator=torch.Generator().manual_seed(30))\n",
    "\n",
    "train_dataloader = DataLoader(dataset=data_train, batch_size=BATCH_SIZE, shuffle=False)\n",
    "val_dataloader = DataLoader(dataset=data_val, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define NN: taken from https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n",
    "# 2 conv layers, followed by 3 fully connected layers\n",
    "# This is the network I used in the end\n",
    "\n",
    "class NN_model(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(NN_model, self).__init__()\n",
    "        # 29 input image channels (bands), 2x2 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(n_channels, 35, 2, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(35, 50, 2, padding=1)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(50*2*2, 120)  \n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Yealds ab 36% acc.\n",
    "# With Adam: 45%\n",
    "# data augmentation - 46%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dense_model(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(dense_model, self).__init__()\n",
    "        # 29 input image channels (bands), 2x2 square convolution\n",
    "        # kernel\n",
    "        self.fc1 = nn.Linear(n_channels*5*5, 145)\n",
    "        self.fc2 = nn.Linear(145, 145)\n",
    "        self.fc3 = nn.Linear(145, 29)\n",
    "        self.fc4 = nn.Linear(29, 29)\n",
    "        self.fc5 = nn.Linear(29, n_classes)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = F.softmax(self.fc5(x), dim=1)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "# Yelds ab. 41% acc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TreeClass_net = NN_model()\n",
    "\n",
    "# Loss function & optimizer:\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.SGD(TreeClass_net.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer = optim.Adam(TreeClass_net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet34: https://blog.paperspace.com/writing-resnet-from-scratch-in-pytorch/\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride = 1, downsample = None):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "                        nn.Conv2d(in_channels, out_channels, kernel_size = 3, stride = stride, padding = 1),\n",
    "                        nn.BatchNorm2d(out_channels),\n",
    "                        nn.ReLU())\n",
    "        self.conv2 = nn.Sequential(\n",
    "                        nn.Conv2d(out_channels, out_channels, kernel_size = 3, stride = 1, padding = 1),\n",
    "                        nn.BatchNorm2d(out_channels))\n",
    "        self.downsample = downsample\n",
    "        self.relu = nn.ReLU()\n",
    "        self.out_channels = out_channels\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        if self.downsample:\n",
    "            residual = self.downsample(x)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "    \n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes = 10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.inplanes = 64\n",
    "        self.conv1 = nn.Sequential(\n",
    "                        nn.Conv2d(29, 64, kernel_size = 3, stride = 2, padding = 3),\n",
    "                        nn.BatchNorm2d(64),\n",
    "                        nn.ReLU())\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n",
    "        self.layer0 = self._make_layer(block, 64, layers[0], stride = 1)\n",
    "        self.layer1 = self._make_layer(block, 128, layers[1], stride = 2)\n",
    "        self.layer2 = self._make_layer(block, 256, layers[2], stride = 2)\n",
    "        self.layer3 = self._make_layer(block, 512, layers[3], stride = 2)\n",
    "        self.avgpool = nn.AvgPool2d(5, stride=1)\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "        \n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes:\n",
    "            \n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes, kernel_size=1, stride=stride),\n",
    "                nn.BatchNorm2d(planes),\n",
    "            )\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer0(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "\n",
    "        # x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "\n",
    "TreeClass_net = ResNet(ResidualBlock, [3, 4, 6, 3])\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(TreeClass_net.parameters(), lr=0.01, weight_decay = 0.001)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43944 687\n",
      "[EPOCH 1] loss: 1.341\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m outputs \u001b[38;5;241m=\u001b[39m TreeClass_net(inputs\u001b[38;5;241m.\u001b[39mfloat())\n\u001b[0;32m     19\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m---> 20\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# print statistics\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    491\u001b[0m     )\n\u001b[1;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\autograd\\__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the Network:\n",
    "\n",
    "N_EPOCHS = 50\n",
    "n_iterations = math.ceil(total_samples/BATCH_SIZE)\n",
    "print(total_samples, n_iterations)\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_dataloader):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = TreeClass_net(inputs.float())\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f'[EPOCH {epoch + 1}] loss: {running_loss / n_iterations:.3f}')\n",
    "    \n",
    "\n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model:\n",
    "torch.save(TreeClass_net.state_dict(), path+'TreeClassifier_Luca_cnn.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:  3 3 3 6 3 6 3 5 3 6 6 3 6 6 3 5 6 3 3 3 6 5 3 6 3 3 5 5 5 5 3 5\n",
      "Actual: 4 8 8 5 3 5 5 5 3 6 6 7 6 6 3 5 5 2 3 3 6 0 4 6 7 0 6 6 6 5 7 6\n"
     ]
    }
   ],
   "source": [
    "# Test network on example validation data:\n",
    "dataiter = iter(val_dataloader)\n",
    "val_input, val_labels = next(dataiter)\n",
    "\n",
    "outputs = TreeClass_net(val_input.float())\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predictions: ', ' '.join(f'{predicted[j]}' for j in range(len(val_labels))))\n",
    "print('Actual:', ' '.join(f'{val_labels[j]}' for j in range(len(val_labels))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 8788 test tree species: 46.040 %\n"
     ]
    }
   ],
   "source": [
    "# Test overall performance:\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in val_dataloader:\n",
    "        val_input, labels = data\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = TreeClass_net(val_input.float())\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the {len(data_val)} test tree species: {100 * correct / total:3.3f} %')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
